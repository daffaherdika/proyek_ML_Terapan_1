# -*- coding: utf-8 -*-
"""Proyek Pertama.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z714tI1vZQyCmxb6FGh-_p4wh-YbmqEU

# Project Pertama: Predictive Analytics

## Import Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import warnings
warnings.filterwarnings('ignore')

"""## Data Loading"""

# Load dataset daftar harga rumah
file_path = '/content/DATA RUMAH.xlsx'
rumah = pd.read_excel(file_path)
rumah

"""## Exploratory Data Analysis

### Deskripsi Variabel

**Insight Statistik Deskriptif**

Statistik deskriptif membantu kita memahami distribusi awal dari fitur numerik seperti harga, luas tanah, dan bangunan. Nilai mean, min, dan max bisa menunjukkan kemungkinan adanya outlier atau ketimpangan distribusi.
"""

# Menampilkan 5 data pertama
print("5 data pertama:")
print(rumah.head)

# Menampilkan statistik deskriptif
print("\nStatistik deskriptif:")
print(rumah.describe())

# Menampilkan informasi dataset
print("\nInformasi dataset:")
print(rumah.info())

# Memeriksa jumlah baris dan kolom
print(f"Jumlah baris: {rumah.shape[0]}")
print(f"Jumlah kolom: {rumah.shape[1]}")

"""### Menangani Missing Value

**Pemeriksaan Missing Value**

Penting untuk mengetahui apakah ada nilai kosong (missing) dalam dataset karena dapat mempengaruhi performa model. Pada kasus ini, tidak ditemukan nilai kosong sehingga tidak perlu proses imputasi.
"""

# Memeriksa missing value
print("Jumlah missing value per kolom:")
print(rumah.isnull().sum())

"""### Menangani Outliers

**Visualisasi Outlier dengan Boxplot**

Boxplot digunakan untuk mendeteksi outlier pada fitur numerik. Nilai yang berada jauh di luar box (di luar whisker) dianggap sebagai outlier dan bisa dipertimbangkan untuk dibuang agar model tidak bias.
"""

sns.boxplot(x=rumah['LT'])

sns.boxplot(x=rumah['LB'])

sns.boxplot(x=rumah['KT'])

sns.boxplot(x=rumah['KM'])

sns.boxplot(x=rumah['GRS'])

# Ambil hanya kolom numerikal
numeric_cols = rumah.select_dtypes(include='number').columns
# Hitung Q1, Q3, dan IQR hanya untuk kolom numerikal
Q1 = rumah[numeric_cols].quantile(0.25)
Q3 = rumah[numeric_cols].quantile(0.75)
IQR = Q3 - Q1
# Buat filter untuk menghapus baris yang mengandung outlier di kolom numerikal
filter_outliers = ~((rumah[numeric_cols] < (Q1 - 1.5 * IQR)) |
                    (rumah[numeric_cols] > (Q3 + 1.5 * IQR))).any(axis=1)
# Terapkan filter ke dataset asli (termasuk kolom non-numerikal)
rumah = rumah[filter_outliers]
# Cek ukuran dataset setelah outlier dihapus
rumah.shape

"""### Univariate Analysis"""

numerical_features = ['HARGA', 'LT', 'LB', 'KT', 'KM', 'GRS']

"""#### Numerical Features"""

rumah.hist(bins=50, figsize=(20,15))
plt.show()

"""## Multivariate Analysis

### Numerical Features
"""

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(rumah, diag_kind = 'kde')

"""**Korelasi antar Fitur**

Heatmap korelasi menunjukkan hubungan antar variabel numerik. Korelasi tinggi antara LB (luas bangunan) dan HARGA menunjukkan bahwa luas bangunan adalah prediktor kuat harga rumah.
"""

# Korelasi antar variabel numerik
plt.figure(figsize=(12, 10))
correlation = rumah[numeric_cols].corr()
sns.heatmap(correlation, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Matriks Korelasi Variabel Numerik')
plt.show()

"""## Data Preparation"""

# Menghapus kolom 'NO'
if 'NO' in rumah.columns:
    rumah = rumah.drop('NO', axis=1)
    print("\nKolom 'NO' telah dihapus karena tidak dibutuhkan")

# Menghapus kolom 'NAMA RUMAH'
if 'NAMA RUMAH' in rumah.columns:
    rumah = rumah.drop('NAMA RUMAH', axis=1)
    print("\nKolom 'NAMA RUMAH' telah dihapus karena tidak dibutuhkan")

"""### Train-Test-Split

**Pembagian Data Latih dan Uji**

Data dibagi menjadi data latih dan uji untuk memastikan model dievaluasi pada data yang belum pernah dilihat sebelumnya. Hal ini penting untuk menghindari overfitting.
"""

X = rumah.drop(["HARGA"],axis =1)
y = rumah["HARGA"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 111)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""### Standarisasi

**Proses Standarisasi**

Standarisasi digunakan agar fitur numerik berada pada skala yang seragam. Ini penting terutama untuk algoritma seperti KNN yang sensitif terhadap skala data.
"""

numerical_features = ['LT', 'LB', 'KT', 'KM', 'GRS']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].describe().round(4)

"""## Model Development"""

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['KNN', 'RandomForest', 'Boosting'])

"""### KNN

**Model K-Nearest Neighbors (KNN)**

KNN memprediksi berdasarkan tetangga terdekat. Model ini sederhana namun sensitif terhadap outlier dan skala fitur.
"""

knn = KNeighborsRegressor(n_neighbors=3)
knn.fit(X_train, y_train)

models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""### Random Forest

**Model Random Forest**

Model ini menggunakan banyak pohon keputusan dan melakukan voting untuk menghasilkan prediksi. Cocok untuk menangani data non-linear dan memberikan performa yang stabil.
"""

# buat model prediksi
RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=111, n_jobs=-1)
RF.fit(X_train, y_train)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""### Bossting Algorithm

**Model AdaBoost**

AdaBoost memperbaiki kelemahan model-model dasar secara iteratif. Cenderung lebih sensitif terhadap noise, namun cukup akurat pada dataset yang bersih.
"""

boosting = AdaBoostRegressor(learning_rate=0.05, random_state=111)
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""## Evaluasi Model"""

# Lakukan scaling terhadap fitur numerik pada X_test sehingga memiliki rata-rata=0 dan varians=1
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

"""**Evaluasi Model dengan MSE**
Mean Squared Error (MSE) digunakan untuk mengevaluasi performa model regresi. Nilai MSE yang lebih rendah menunjukkan prediksi yang lebih akurat.
"""

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}

# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

# Panggil mse
mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

# Fungsi untuk menghitung akurasi berdasarkan persentase error (MAPE)
def prediksi_akurasi(y_true, y_pred):
    error = abs(y_pred - y_true)
    mape = error / y_true * 100
    akurasi = 100 - mape
    return akurasi.round(2)

# Ambil nilai y_true sebenarnya
y_true_value = y_test.iloc[0]

# Siapkan dictionary baru untuk menyimpan hasil prediksi & akurasi
hasil_prediksi = {
    'y_true': y_true_value
}

# Hitung prediksi dan akurasi untuk tiap model
for name, model in model_dict.items():
    y_pred = model.predict(prediksi)[0]  # ambil nilai prediksi sebagai angka
    akurasi = prediksi_akurasi(y_true_value, y_pred)

    hasil_prediksi[f'prediksi_{name}'] = y_pred
    hasil_prediksi[f'akurasi_{name}'] = f"{akurasi}%"  # simpan sebagai string untuk dibaca manusia

# Tampilkan hasilnya dalam DataFrame
pd.DataFrame([hasil_prediksi])